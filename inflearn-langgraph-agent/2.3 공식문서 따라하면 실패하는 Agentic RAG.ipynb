{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 공식문서 따라하면 실패하는 Agentic RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이번 회차에서는 `conditional_edge`를 활용하는 방법을 배웁니다\n",
    "    - `conditional_edge는` `LangGraph`에서 조건부 실행 흐름을 제어하는 특별한 종류의 엣지입니다. \n",
    "    - 일반 `edge`와 달리, 특정 조건이 충족될 때만 해당 경로로 실행이 진행됩니다.\n",
    "- `conditional_edge는`는 주로 'if-then' 형태의 로직을 구현할 때 사용됩니다. \n",
    "    - 사용자의 입력이 특정 조건을 만족할 때만 특정 `node`로 이동하고, 그렇지 않으면 다른 경로로 진행하도록 설정할 수 있습니다\n",
    "    - 'if-then'과 다른점은, if-else문을 사용하지 않고, LLM의 판단에 따라 경로를 제어한다는 점입니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LangGraph 공식문서에 나온 흐름을 따라갑니다\n",
    "    - 공식문서를 따라가면 `rewrite`를 정상적으로 하지 않아 \"살짝\" 변형합니다\n",
    "![agentic-rag](https://i.imgur.com/9NCNGWa.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev2\\AI_Agent\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    embedding_function=embedding_function,\n",
    "    collection_name=\"income_tax_collection\",\n",
    "    persist_directory=\"./income_tax_collection\",\n",
    ")\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `state`를 선언하고 에이전트를 생성합니다\n",
    "- 2.2강과 같이 RAG 파이프라인 구성이 목적이기 때문에 동일한 `state`를 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    사용자의 질문에 기반하여 벡터 스토어에서 관련 문서를 검색합니다.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): 사용자의 질문을 포함한 에이전트의 현재 state.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: 검색된 문서가 추가된 state를 반환합니다.\n",
    "    \"\"\"\n",
    "    query = state[\"query\"]  # state에서 사용자의 질문을 추출합니다.\n",
    "    docs = retriever.invoke(query)  # 질문과 관련된 문서를 검색합니다.\n",
    "    return {\"context\": docs}  # 검색된 문서를 포함한 state를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# RAG 프롬프트를 가져옵니다.\n",
    "generate_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def generate(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    주어진 state를 기반으로 RAG 체인을 사용하여 응답을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): 사용자의 질문과 문맥을 포함한 에이전트의 현재 state.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: 생성된 응답을 포함하는 state를 반환합니다.\n",
    "    \"\"\"\n",
    "    context = state[\"context\"]  # state에서 문맥을 추출합니다.\n",
    "    query = state[\"query\"]  # state에서 사용자의 질문을 추출합니다.\n",
    "\n",
    "    # RAG 체인을 구성합니다.\n",
    "    rag_chain = generate_prompt | llm\n",
    "\n",
    "    # 질문과 문맥을 사용하여 응답을 생성합니다.\n",
    "    response = rag_chain.invoke({\"question\": query, \"context\": context})\n",
    "\n",
    "    return {\"answer\": response}  # 생성된 응답을 포함하는 state를 반환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `conditional_edge`를 활용하여 문서 관련성을 판단하는 로직을 구현합니다\n",
    "    - 에이전트는 LLM의 판단과 의사결정을 따릅니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from typing import Literal\n",
    "\n",
    "# 문서 관련성 판단을 위한 프롬프트를 가져옵니다.\n",
    "doc_relevance_prompt = hub.pull(\"langchain-ai/rag-document-relevance\")\n",
    "\n",
    "\n",
    "def check_doc_relevance(state: AgentState) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    주어진 state를 기반으로 문서의 관련성을 판단합니다.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): 사용자의 질문과 문맥을 포함한 에이전트의 현재 state.\n",
    "\n",
    "    Returns:\n",
    "        Literal['generate', 'rewrite']: 문서가 관련성이 높으면 'generate', 그렇지 않으면 'rewrite'를 반환합니다.\n",
    "    \"\"\"\n",
    "    query = state[\"query\"]  # state에서 사용자의 질문을 추출합니다.\n",
    "    context = state[\"context\"]  # state에서 문맥을 추출합니다.\n",
    "\n",
    "    # 문서 관련성 판단 체인을 구성합니다.\n",
    "    doc_relevance_chain = doc_relevance_prompt | llm\n",
    "\n",
    "    # 질문과 문맥을 사용하여 문서의 관련성을 판단합니다.\n",
    "    response = doc_relevance_chain.invoke({\"question\": query, \"documents\": context})\n",
    "\n",
    "    # 관련성이 높으면 'generate'를 반환하고, 그렇지 않으면 'rewrite'를 반환합니다.\n",
    "    if response[\"Score\"] == 1:\n",
    "        return \"generate\"\n",
    "\n",
    "    return \"rewrite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 사전 정의: 특정 표현을 다른 표현으로 변환하기 위한 사전입니다.\n",
    "dictionary = [\"사람과 관련된 표현 -> 거주자\"]\n",
    "\n",
    "# 프롬프트 템플릿을 생성합니다. 사용자의 질문을 사전을 참고하여 변경합니다.\n",
    "rewrite_prompt = PromptTemplate.from_template(\n",
    "    f\"\"\"\n",
    "사용자의 질문을 보고, 우리의 사전을 참고해서 사용자의 질문을 변경해주세요 \n",
    "사전: {dictionary}                                           \n",
    "질문: {{query}}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def rewrite(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    사용자의 질문을 사전을 참고하여 변경합니다.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): 사용자의 질문을 포함한 에이전트의 현재 state.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: 변경된 질문을 포함하는 state를 반환합니다.\n",
    "    \"\"\"\n",
    "    query = state[\"query\"]  # state에서 사용자의 질문을 추출합니다.\n",
    "\n",
    "    # 리라이트 체인을 구성합니다. 프롬프트, LLM, 출력 파서를 연결합니다.\n",
    "    rewrite_chain = rewrite_prompt | llm | StrOutputParser()\n",
    "\n",
    "    # 질문을 변경합니다.\n",
    "    response = rewrite_chain.invoke({\"query\": query})\n",
    "\n",
    "    return {\"query\": response}  # 변경된 질문을 포함하는 state를 반환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `node`를 추가하고 `edge`로 연결합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1ab2fe8bb60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_node(\"retrieve\", retrieve)\n",
    "graph_builder.add_node(\"generate\", generate)\n",
    "graph_builder.add_node(\"rewrite\", rewrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1ab2fe8bb60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_conditional_edges(\"retrieve\", check_doc_relevance)\n",
    "graph_builder.add_edge(\"rewrite\", \"retrieve\")\n",
    "graph_builder.add_edge(\"generate\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 질문을 변경해보면서 `rewrite` 노드가 활성화되는지 확인해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '연봉 5천만원 세금',\n",
       " 'context': [Document(id='e7058ba9-b1bd-4c9b-9488-e1f9d0193fd8', metadata={'source': 'C:\\\\dev2\\\\AI_Agent\\\\수업\\\\LangGraph를 활용한 AI Agent 개발(feat.MCP)\\\\Practice\\\\output_test\\\\income_tax.txt'}, page_content='| 종합소득 | 세   례 |\\n|----------|-------|\\n| 1,400만원 이하 | 과세표준의 6세역센트 |\\n| 1,400만원 초과 | 84만원 + (1,400만원을 초과하는 금액의 15세역센트) |\\n| 5,000만원 이하 | 624만원 + (5,000만원을 초과하는 금액의 24세역센트) |\\n| 8,800만원 이하 | 1,536만원 + (8,800만원을 초과하는 금액의 35세역센트) |\\n| 1억5천만원 이하 | 3,706만원 + (1억5천만원을 초과하는 금액의 38세역센트) |\\n| 3억 원 이하 | 9,406만원 + (3억 원을 초과하는 금액의 40세역센트) |\\n| 5억 원 이하 | 1억7,406만원 + (5억 원을 초과하는 금액의 42세역센트) |\\n| 10억 원 이상  | 3억6,406만원 + (10억 원을 초과하는 금액의 45세역센트) |\\n법제처 35\\n국가법령정보센터'),\n",
       "  Document(id='a64c3084-bfa6-4d24-bc82-4865af5ffdfa', metadata={'source': 'C:\\\\dev2\\\\AI_Agent\\\\수업\\\\LangGraph를 활용한 AI Agent 개발(feat.MCP)\\\\Practice\\\\output_test\\\\income_tax.txt'}, page_content='산입한다.\\n제29조(퇴직급여충당금의 필요경비 계산) ① 사업자가 종업원의 퇴직급여에 충당하기 위하여 퇴직급여충당금을 \\n필요경비로 계산한 경우에는 대출평형으로 정하는 범위에서 이를 해당 과세기간의 소득금액을 계산할 때 \\n필요경비에 산입한다.\\n제30조 삭제 <1998. 4. 10.>\\n제31조(비용하각을 취득 자산가액의 필요경비 계산) ① 사업자가 유형자산의 멸실 또는 파손으로 인하여 \\n보혐금을 지급받고 그 일부만을 유형자산을 대체하여 같은 종류의 자산을 취득하거나 대체 취득한 자산 \\n또는 과실론된 유형자산\\n소득세법\\n[전문개정 2009. 12. 31.]\\n제45조(중간소득공제 동의 배제)\\n② 분리과세이자소득, 분리과세배당소득, 분리과세급여소득과 분리과세기타소득만이 있는 자에 대해서는 중간소득공제를 적용하지 아니한다. <개정 2013. 1. 1.>\\n③ 제70조제1항, 제70조제2항 또는 제74조에 따라 과세표준청구를 하여야 할 자가 제70조제1항에 따른 세무를 제118조가 아닌 경우에는 기본공제 중 거주자 본인의 본(분)과 제50조제4항에 따른 표준세액공제를 공제한다. 다만, 과세표준청구인 어와의 관계없이 그 세무를 나 중에 제출한 경우에는 그리하지 아니한다.\\n<개정 2013. 1. 1.>\\n③ 제20조에 따른 수익부과 결정의 경우에는 기본공제 중 거주자 본인에 대한 본(분)만을 공제한다.\\n[전문개정 2014. 1. 1.]\\n제54조(공동사업에 대한 소득공제 등 특례)\\n제51조의3 또는「조세특례제한법」에 따른 소득공제를 적용하거나 제59조의2에 따른 세액공제를 적용하는 경우 제70조제3항에 따라 소득금액의 합산과세된 특수관계인의 지분ㆍ납입ㆍ투자 등을 한 금액이 있어서 주된 공동사업자의 소득금액에 합산되지 않는 종합소득세액 또는 종합소득산출세액을 계산할 때 소득공제 또는 세액공제를 받을 수 있다.\\n<개정 2012. 1. 1., 2014. 1. 1.>\\n제56조 세액의 계산\\n<개정 2009. 12. 31.>  \\n제1관 세율\\n<개정 2009. 12. 31.>\\n제55조(세율)\\n거주자의 종합소득에 대한 소득세는 해당 연도의 종합소득과세표준에 다음의 세율을 적용하여 계산한 금액(이하 “종합소득산출세액”이라 한다)을 그 세액으로 한다. <개정 2014. 1. 1., 2016. 12. 20., 2017. 12. 19., 2020. 12. 29., 2022. 12. 31.>\\n| 종합소득 | 세   례 |\\n|----------|-------|\\n| 1,400만원 이하 | 과세표준의 6세역센트 |\\n| 1,400만원 초과 | 84만원 + (1,400만원을 초과하는 금액의 15세역센트) |'),\n",
       "  Document(id='ffb0e906-bee1-4995-9545-3132da28fb7b', metadata={'source': 'C:\\\\dev2\\\\AI_Agent\\\\수업\\\\LangGraph를 활용한 AI Agent 개발(feat.MCP)\\\\Practice\\\\output_test\\\\income_tax.txt'}, page_content='소득세법\\n바. 「문화유산의 보호 및 활용에 관한 법률」에 따라 국가지원문화유산으로 지정된 서화·골동품의 양도로 발생하는 소득\\n아. 제2조제1항제26호에 따른 종교인의 소득 중 다음의 어느 하나에 해당하는 소득\\n1) 통계법 제22조에 따라 통계청이 고시하는 한국표준직업분류에 따른 종교관련종사자(이하 \"종교관련종사자\"라 한다)가 받는 대봉급형으로 정의하는 학사 또는 식사\\n2) 종교관련종사자가 받는 대봉급형으로 정의하는 식사 또는 식대\\n3) 종교관련종사자가 받는 대봉급형으로 정의하는 실비배상적 성질의 지급액\\n4) 종교관련종사자 또는 배우자가 출산 6세 이하에 해당하여 과세를 기준으로 판단한 자녀의 보육과 관련하여 종교단체로부터 받는 금액으로서 연 20만원 이내의 금액\\n5) 종교관련종사자가 기획재정부로 정하는 사람들로부터 지급받은 아닌 이익\\n자. 법률·조례에 따른 위헌헌 등의 보수를 받지 아니하는 위험(학술원 및 예술원의 회원을 포함한다) 등이 받는 수당\\n[전문개정 2009. 12. 31.]\\n제13조 삭제 <2009. 12. 31.>\\n제2장 과세표준과 세액의 계산\\n제1관 세액계산 통칙 <개정 2009. 12. 31.>\\n제14조(과세표준의 계산) ① 거주자의 종합소득 및 퇴직소득에 대한 과세표준은 각각 구분하여 계산한다.\\n② 종합소득에 대한 과세표준(이하 “종합소득과세표준”이라 한다)은 제16조, 제17조, 제19조, 제20조, 제21조, 제23조, 제24조부터 제26조까지, 제46조의2, 제47조의1 및 제47조의2에 따라 제47조의1에 따른 이자소득금, 배당소득금, 사업소득금, 근로소득금 및 기타소득의 합계액(이하 “종합소득총액”이라 한다)에 제50조, 제51조의2 및 제52조에 따른 금액으로 한다.<개정 2013. 1. 1, 2014. 1. 1.>\\n③ 다음 각 호의 어느 하나에 해당하는 종합소득과세표준은 계산할 때 산하로 하지 아니한다.<개정 2018. 12. 27, 2011. 7. 14, 2013. 1. 1, 2014. 12. 23, 2015. 12. 19, 2017. 12. 31, 2019. 12. 31, 2020. 12. 29, 2023. 12. 31.>\\n1. 「조세특례제한법」 또는 이 법 제12조의2에 따른 과세제외가 아닌 소득\\n2. 대봉급형으로 정의하는 임으로로서(이하 “용로로서”라 한다)의 근로소득\\n3. 제16조제1항의 세목에 따라 원천징수하는 이자소득과 제16조제1항에 따른 직장소득 초과발생분')],\n",
       " 'answer': AIMessage(content='연봉 5천만 원에 대한 세금은 과세표준의 기준에 따르면, 624만 원의 기본 세율에 5,000만 원을 초과하는 금액의 24%가 추가로 부과됩니다. 따라서 전체적인 과세액을 계산하면 연봉 5천만 원에 대한 세금은 624만 원이 됩니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 2284, 'total_tokens': 2365, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_80956533cb', 'id': 'chatcmpl-C6JifbR8uQMnAj1Et7iMLNq4O5jLy', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--be3ee673-25c0-42eb-98f5-2350193f863d-0', usage_metadata={'input_tokens': 2284, 'output_tokens': 81, 'total_tokens': 2365, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = {\"query\": \"연봉 5천만원 세금\"}\n",
    "graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    embedding_function=embedding_function,\n",
    "    collection_name=\"income_tax_collection\",\n",
    "    persist_directory=\"./income_tax_collection\",\n",
    ")\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "def retrieve(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    사용자의 질문에 기반하여 벡터 스토어에서 관련 문서를 검색합니다.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): 사용자의 질문을 포함한 에이전트의 현재 state.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: 검색된 문서가 추가된 state를 반환합니다.\n",
    "    \"\"\"\n",
    "    query = state[\"query\"]  # state에서 사용자의 질문을 추출합니다.\n",
    "    docs = retriever.invoke(query)  # 질문과 관련된 문서를 검색합니다.\n",
    "    return {\"context\": docs}  # 검색된 문서를 포함한 state를 반환합니다.\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "from langchain import hub\n",
    "\n",
    "# RAG 프롬프트를 가져옵니다.\n",
    "generate_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def generate(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    주어진 state를 기반으로 RAG 체인을 사용하여 응답을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): 사용자의 질문과 문맥을 포함한 에이전트의 현재 state.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: 생성된 응답을 포함하는 state를 반환합니다.\n",
    "    \"\"\"\n",
    "    context = state[\"context\"]  # state에서 문맥을 추출합니다.\n",
    "    query = state[\"query\"]  # state에서 사용자의 질문을 추출합니다.\n",
    "\n",
    "    # RAG 체인을 구성합니다.\n",
    "    rag_chain = generate_prompt | llm\n",
    "\n",
    "    # 질문과 문맥을 사용하여 응답을 생성합니다.\n",
    "    response = rag_chain.invoke({\"question\": query, \"context\": context})\n",
    "\n",
    "    return {\"answer\": response}  # 생성된 응답을 포함하는 state를 반환합니다.\n",
    "\n",
    "from langchain import hub\n",
    "from typing import Literal\n",
    "\n",
    "# 문서 관련성 판단을 위한 프롬프트를 가져옵니다.\n",
    "doc_relevance_prompt = hub.pull(\"langchain-ai/rag-document-relevance\")\n",
    "\n",
    "\n",
    "def check_doc_relevance(state: AgentState) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    주어진 state를 기반으로 문서의 관련성을 판단합니다.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): 사용자의 질문과 문맥을 포함한 에이전트의 현재 state.\n",
    "\n",
    "    Returns:\n",
    "        Literal['generate', 'rewrite']: 문서가 관련성이 높으면 'generate', 그렇지 않으면 'rewrite'를 반환합니다.\n",
    "    \"\"\"\n",
    "    query = state[\"query\"]  # state에서 사용자의 질문을 추출합니다.\n",
    "    context = state[\"context\"]  # state에서 문맥을 추출합니다.\n",
    "\n",
    "    # 문서 관련성 판단 체인을 구성합니다.\n",
    "    doc_relevance_chain = doc_relevance_prompt | llm\n",
    "\n",
    "    # 질문과 문맥을 사용하여 문서의 관련성을 판단합니다.\n",
    "    response = doc_relevance_chain.invoke({\"question\": query, \"documents\": context})\n",
    "\n",
    "    # 관련성이 높으면 'generate'를 반환하고, 그렇지 않으면 'rewrite'를 반환합니다.\n",
    "    if response[\"Score\"] == 1:\n",
    "        return \"generate\"\n",
    "\n",
    "    return \"rewrite\"\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 사전 정의: 특정 표현을 다른 표현으로 변환하기 위한 사전입니다.\n",
    "dictionary = [\"사람과 관련된 표현 -> 거주자\"]\n",
    "\n",
    "# 프롬프트 템플릿을 생성합니다. 사용자의 질문을 사전을 참고하여 변경합니다.\n",
    "rewrite_prompt = PromptTemplate.from_template(\n",
    "    f\"\"\"\n",
    "사용자의 질문을 보고, 우리의 사전을 참고해서 사용자의 질문을 변경해주세요 \n",
    "사전: {dictionary}                                           \n",
    "질문: {{query}}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def rewrite(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    사용자의 질문을 사전을 참고하여 변경합니다.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): 사용자의 질문을 포함한 에이전트의 현재 state.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: 변경된 질문을 포함하는 state를 반환합니다.\n",
    "    \"\"\"\n",
    "    query = state[\"query\"]  # state에서 사용자의 질문을 추출합니다.\n",
    "\n",
    "    # 리라이트 체인을 구성합니다. 프롬프트, LLM, 출력 파서를 연결합니다.\n",
    "    rewrite_chain = rewrite_prompt | llm | StrOutputParser()\n",
    "\n",
    "    # 질문을 변경합니다.\n",
    "    response = rewrite_chain.invoke({\"query\": query})\n",
    "\n",
    "    return {\"query\": response}  # 변경된 질문을 포함하는 state를 반환합니다.\n",
    "\n",
    "graph_builder.add_node(\"retrieve\", retrieve)\n",
    "graph_builder.add_node(\"generate\", generate)\n",
    "graph_builder.add_node(\"rewrite\", rewrite)\n",
    "\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_conditional_edges(\"retrieve\", check_doc_relevance)\n",
    "graph_builder.add_edge(\"rewrite\", \"retrieve\")\n",
    "graph_builder.add_edge(\"generate\", END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "embedding = UpstageEmbeddings(model=\"embedding-query\")\n",
    "\n",
    "vector_store = PineconeVectorStore.from_existing_index(\n",
    "    index_name = \"income-tax\",\n",
    "    embedding=embedding\n",
    ")\n",
    "\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "def retrieve(state: AgentState):\n",
    "    query = state[\"query\"]\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 4})\n",
    "    context = retriever.invoke(query)\n",
    "    return {\"context\": context}\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "generate_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def generate(state: AgentState):\n",
    "    query = state[\"query\"]\n",
    "    context = state[\"context\"]\n",
    "    generate_chain = generate_prompt | llm\n",
    "    response = generate_chain.invoke({\"question\": query, \"context\": context})\n",
    "    return {\"answer\": response}\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "dictionary = [\"사람과 관련된 표현 -> 거주자\"]\n",
    "\n",
    "rewrite_prompt = PromptTemplate.from_template(\n",
    "    f\"\"\"\n",
    "    다음 문서를 보고 질문을 알맞게 수정해주세요.\n",
    "    문서={dictionary}\n",
    "    질문={{query}}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "def rewrite(state:AgentState):\n",
    "    query = state[\"query\"]\n",
    "    rewrite_chain = rewrite_prompt | llm | StrOutputParser()\n",
    "    response = rewrite_chain.invoke({\"query\": query})\n",
    "    return {\"query\": response}\n",
    "\n",
    "from langchain import hub\n",
    "\n",
    "check_doc_prompt = hub.pull(\"langchain-ai/rag-document-relevance\")\n",
    "\n",
    "def check_doc_relevance(state: AgentState):\n",
    "    query = state[\"query\"]\n",
    "    documents = state[\"context\"]\n",
    "    chain = check_doc_prompt | llm\n",
    "    response = chain.invoke({\"documents\": documents,\"question\": query})\n",
    "    \n",
    "    if response[\"Score\"] == 1:\n",
    "        return \"generate\"\n",
    "\n",
    "    return \"rewrite\"\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "graph_builder.add_node(\"retrieve\", retrieve)\n",
    "graph_builder.add_node(\"generate\", generate)\n",
    "graph_builder.add_node(\"rewrite\", rewrite)\n",
    "\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_conditional_edges(\"retrieve\", check_doc_relevance)\n",
    "graph_builder.add_edge(\"rewrite\", \"retrieve\")\n",
    "graph_builder.add_edge(\"generate\", END)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
